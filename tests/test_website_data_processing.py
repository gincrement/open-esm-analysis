# SPDX-FileCopyrightText: openmod-tracker contributors
#
# SPDX-License-Identifier: MIT


"""Test suite for website data processing functions.

Tests were generated by Claude Sonnet 4.5 using the following prompt:

> For each method in `website/**/.py` that returns a pandas series or dataframe, create a concise test function to ensure it is processing the data as expected.
> You can use the actual files in `user_analysis/output` and `inventory/output` to test against.
> If there is a conditional in the method, write a different test for each state of the conditional.

Then:
- Refactor the tests you've added to use `pytest.mark.parametrize` to test different parameter variations within tests.
- Assume streamlit can be imported and move the import to the top of the file rather than having it within tests.
- Turn any duplicate calls to functions (e.g., reading a CSV, creating a table) with the same arguments into class-level pytest fixtures.

I have then reviewed the generated tests and made minor adjustments for clarity.
"""

import importlib.util
import sys
from pathlib import Path

import numpy as np
import pandas as pd
import pytest
import streamlit as st

# Define paths
WEBSITE_DIR = Path(__file__).parent.parent / "website"
PROJ_DIR = Path(__file__).parent.parent
USER_STATS_DIR = PROJ_DIR / "user_analysis" / "output"
INVENTORY_DIR = PROJ_DIR / "inventory" / "output"

# Add website module to path
sys.path.insert(0, str(WEBSITE_DIR))


def load_module_from_file(filepath: Path, module_name: str):
    """Load a Python module from a file path."""
    spec = importlib.util.spec_from_file_location(module_name, filepath)
    if spec is None or spec.loader is None:
        raise ImportError(f"Cannot load module from {filepath}")
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module


# Import modules
util = load_module_from_file(WEBSITE_DIR / "util.py", "util")
main_page = load_module_from_file(
    WEBSITE_DIR / "âš¡ï¸_Tool_Repository_Metrics.py", "main_page"
)
user_analysis = load_module_from_file(
    WEBSITE_DIR / "pages" / "1_ðŸ‘¤_Deep_Dive_-_User_Interaction_Analysis.py",
    "user_analysis",
)
dev_metrics = load_module_from_file(
    WEBSITE_DIR / "pages" / "2_ðŸ“Š_Deep_Dive_-_Project_Development_Metrics.py",
    "dev_metrics",
)


# ===== Tests for util.py =====


class TestUtilFunctions:
    """Tests for utility functions in util.py."""

    @pytest.fixture
    def numeric_series(self):
        """Create a numeric series for testing."""
        return pd.Series([1, 2, 3, 4, 5], name="test_numeric")

    @pytest.fixture
    def datetime_series(self):
        """Create a datetime series for testing."""
        return pd.Series(
            pd.date_range("2020-01-01", periods=5, freq="D"), name="test_datetime"
        )

    @pytest.fixture
    def string_series(self):
        """Create a string series for testing."""
        return pd.Series(["a", "b", "c"], dtype="string", name="test_string")

    @pytest.fixture
    def categorical_series(self):
        """Create a categorical series for testing."""
        return pd.Series(
            ["cat1", "cat2", "cat1"], dtype="category", name="test_category"
        )

    @pytest.fixture
    def list_series(self):
        """Create a series containing lists."""
        return pd.Series([[1, 2], [3, 4], [5, 6]], name="test_list")

    @pytest.fixture
    def series_with_nan(self):
        """Create a series with NaN values."""
        return pd.Series([1, 2, np.nan, 4, np.nan], name="test_nan")

    @pytest.mark.parametrize(
        ("series_fixture", "expected"),
        [
            ("datetime_series", True),
            ("numeric_series", False),
            ("string_series", False),
        ],
    )
    def test_is_datetime_column(self, series_fixture, expected, request):
        """Test datetime detection with different column types."""
        series = request.getfixturevalue(series_fixture)
        assert util.is_datetime_column(series) is expected

    @pytest.mark.parametrize(
        ("series_fixture", "expected"),
        [
            ("numeric_series", True),
            ("string_series", False),
            ("datetime_series", False),
        ],
    )
    def test_is_numeric_column(self, series_fixture, expected, request):
        """Test numeric detection with different column types."""
        series = request.getfixturevalue(series_fixture)
        assert util.is_numeric_column(series) is expected

    @pytest.mark.parametrize(
        ("series_fixture", "expected"),
        [
            ("string_series", True),
            ("categorical_series", True),
            ("numeric_series", False),
        ],
    )
    def test_is_categorical_column(self, series_fixture, expected, request):
        """Test categorical detection with different column types."""
        series = request.getfixturevalue(series_fixture)
        assert util.is_categorical_column(series) is expected

    @pytest.mark.parametrize(
        ("series_fixture", "expected"),
        [("list_series", True), ("numeric_series", False)],
    )
    def test_is_list_column(self, series_fixture, expected, request):
        """Test list detection with different column types."""
        series = request.getfixturevalue(series_fixture)
        assert util.is_list_column(series) is expected

    def test_is_list_column_with_nan(self):
        """Test list detection with NaN values."""
        series = pd.Series([[1, 2], np.nan, [3, 4]], name="test_list_nan")
        assert util.is_list_column(series) is True

    def test_nan_filter_removes_nans(self, series_with_nan):
        """Test that nan_filter returns mask excluding NaN values."""
        result = util.nan_filter(series_with_nan)
        assert isinstance(result, pd.Series)
        assert result.dtype == bool
        assert result.sum() == 3  # Only 3 non-NaN values

    def test_nan_filter_all_valid(self, numeric_series):
        """Test nan_filter with no NaN values."""
        result = util.nan_filter(numeric_series)
        assert result.all()
        assert len(result) == len(numeric_series)


# ===== Tests for main page (âš¡ï¸_Tool_Repository_Metrics.py) =====


class TestMainPageFunctions:
    """Tests for main page data processing functions."""

    @pytest.fixture(scope="class")
    def vis_table(self):
        """Create visualization table from actual data (class-level fixture)."""
        return main_page.create_vis_table(INVENTORY_DIR, USER_STATS_DIR)

    @pytest.fixture(scope="class")
    def interaction_dataframe(self):
        """Load interaction dataframe from CSV (class-level fixture)."""
        return main_page.interaction_df(USER_STATS_DIR / "repo_interactions.csv")

    @pytest.fixture(scope="class")
    def repo_interactions_timeseries(self):
        """Create repo interactions timeseries (class-level fixture)."""
        return main_page._create_repo_interactions_timeseries(USER_STATS_DIR)

    @pytest.fixture
    def sample_stats_df(self):
        """Create a sample stats dataframe."""
        return pd.DataFrame(
            {
                "stargazers_count": ["100", "200", "50"],
                "commit_stats.total_committers": ["10", "20", "5"],
                "commit_stats.dds": ["0.5", "0.7", "0.3"],
                "forks_count": ["30", "40", "10"],
                "dependent_repos_count": ["5", "10", "2"],
                "last_month_downloads": ["1000", "2000", "500"],
                "category": ["cat1,cat2", "cat2", "cat1"],
                "created_at": ["2020-01-01", "2019-01-01", "2021-01-01"],
                "pushed_at": ["2024-01-01", "2023-01-01", None],
                "updated_at": ["2024-01-01", "2023-01-01", "2024-06-01"],
            },
            index=["tool1", "tool2", "tool3"],
        )

    @pytest.fixture
    def sample_tools_df(self):
        """Create a sample tools dataframe."""
        return pd.DataFrame(
            {
                "name": ["Tool One", "Tool Two", "Tool Three"],
                "url": [
                    "https://github.com/org1/tool1",
                    "https://github.com/org2/tool2",
                    "https://github.com/org3/tool3",
                ],
                "language": ["Python", "Jupyter Notebook", "R"],
                "homepage": ["http://tool1.org", None, "http://tool3.org"],
            },
            index=["tool1", "tool2", "tool3"],
        )

    @pytest.fixture
    def sample_docs_df(self):
        """Create a sample docs dataframe."""
        return pd.DataFrame(
            {
                "pages": ["http://docs1.org", None, None],
                "rtd": [None, "http://rtd2.org", None],
                "wiki": [None, None, "http://wiki3.org"],
            },
            index=["tool1", "tool2", "tool3"],
        )

    def test_create_vis_table_structure(self, vis_table):
        """Test create_vis_table returns correctly structured DataFrame."""
        df = vis_table

        # Check it's a DataFrame
        assert isinstance(df, pd.DataFrame)

        # Check expected columns exist
        expected_cols = [
            "name_with_url",
            "Docs",
            "Score",
            "Interactions",
            "Created",
            "Updated",
            "Stars",
            "Contributors",
            "DDS",
            "Forks",
            "Dependents",
            "1 Month Downloads",
            "Category",
            "Language",
        ]
        for col in expected_cols:
            assert col in df.columns, f"Missing column: {col}"

        # Check data types
        assert pd.api.types.is_datetime64_any_dtype(df["Created"])
        assert pd.api.types.is_datetime64_any_dtype(df["Updated"])
        assert pd.api.types.is_numeric_dtype(df["Stars"])
        assert pd.api.types.is_numeric_dtype(df["Contributors"])
        assert pd.api.types.is_numeric_dtype(df["DDS"])

    def test_create_vis_table_language_jupyter_conversion(self, vis_table):
        """Test that Jupyter Notebook is converted to Python."""
        # Check no Jupyter Notebook in language
        assert "jupyter notebook" not in vis_table["Language"].str.lower().values

    def test_create_vis_table_pushed_at_fillna(self, vis_table):
        """Test that pushed_at is filled with updated_at when missing."""
        # Updated should never be NaN if pushed_at was filled
        assert vis_table["Updated"].notna().all()

    def test_interaction_df_structure(self, interaction_dataframe):
        """Test interaction_df returns correct structure."""
        assert isinstance(interaction_dataframe, pd.DataFrame)
        assert "username" in interaction_dataframe.columns
        assert "repo" in interaction_dataframe.columns
        assert pd.api.types.is_datetime64_any_dtype(interaction_dataframe["created"])

    def test_interaction_df_no_missing_critical_fields(self, interaction_dataframe):
        """Test that interaction_df drops rows missing username or repo."""
        assert interaction_dataframe["username"].notna().all()
        assert interaction_dataframe["repo"].notna().all()

    def test_create_repo_interactions_timeseries_structure(
        self, repo_interactions_timeseries
    ):
        """Test _create_repo_interactions_timeseries returns Series with list values."""
        assert isinstance(repo_interactions_timeseries, pd.Series)
        # Values should be numpy arrays
        assert all(
            isinstance(v, np.ndarray) for v in repo_interactions_timeseries.values
        )

    @pytest.mark.parametrize("n_months", [6, 12])
    def test_create_repo_interactions_timeseries_with_different_n_months(
        self, n_months
    ):
        """Test _create_repo_interactions_timeseries with different n_months parameter."""
        result = main_page._create_repo_interactions_timeseries(
            USER_STATS_DIR, n_months=n_months
        )

        assert isinstance(result, pd.Series)

    @pytest.mark.parametrize("resolution", ["7d", "30d"])
    def test_create_repo_interactions_timeseries_with_different_resolution(
        self, resolution
    ):
        """Test _create_repo_interactions_timeseries with different resolution."""
        result = main_page._create_repo_interactions_timeseries(
            USER_STATS_DIR, resolution=resolution
        )

        assert isinstance(result, pd.Series)

    def test_numeric_range_filter_inclusive(self):
        """Test numeric_range_filter includes boundaries."""
        col = pd.Series([1, 2, 3, 4, 5], name="test")
        result = main_page.numeric_range_filter(col, 2, 4)

        assert result.sum() == 3  # 2, 3, 4
        assert result[1]  # index 1 (value 2)
        assert result[3]  # index 3 (value 4)

    def test_numeric_range_filter_with_nan(self):
        """Test numeric_range_filter handles NaN values."""
        col = pd.Series([1, 2, np.nan, 4, 5], name="test")
        result = main_page.numeric_range_filter(col, 2, 4)

        assert result.sum() == 3  # 2, NaN, 4 (NaN is included)
        assert result[2]  # NaN should be included

    def test_date_range_filter_inclusive(self):
        """Test date_range_filter includes boundaries."""
        col = pd.Series(pd.date_range("2020-01-01", periods=5, freq="D"))
        start_date = pd.Timestamp("2020-01-02").date()
        end_date = pd.Timestamp("2020-01-04").date()

        result = main_page.date_range_filter(col, start_date, end_date)

        assert result.sum() == 3  # 2nd, 3rd, 4th

    def test_date_range_filter_with_timezone(self):
        """Test date_range_filter handles timezones."""
        col = pd.Series(
            pd.date_range("2020-01-01", periods=5, freq="D", tz="UTC"), name="test"
        )
        start_date = pd.Timestamp("2020-01-02").date()
        end_date = pd.Timestamp("2020-01-04").date()

        result = main_page.date_range_filter(col, start_date, end_date)

        assert result.sum() == 3

    def test_date_range_filter_with_nan(self):
        """Test date_range_filter handles NaN values."""
        col = pd.Series(
            [pd.Timestamp("2020-01-01"), pd.NaT, pd.Timestamp("2020-01-03")]
        )
        start_date = pd.Timestamp("2020-01-01").date()
        end_date = pd.Timestamp("2020-01-02").date()

        result = main_page.date_range_filter(col, start_date, end_date)

        assert result[1]  # NaN should be included

    def test_categorical_filter_basic(self):
        """Test categorical_filter with basic string matching."""
        col = pd.Series(["a", "b", "c", "a"], dtype="string")
        to_filter = ["a", "c"]

        result = main_page.categorical_filter(col, to_filter)

        assert result.sum() == 3  # Two 'a' and one 'c'

    def test_categorical_filter_with_nan(self):
        """Test categorical_filter includes NaN values."""
        col = pd.Series(["a", "b", None, "c"], dtype="string")
        to_filter = ["a"]

        result = main_page.categorical_filter(col, to_filter)

        assert result.sum() == 2  # One 'a' and one NaN

    def test_list_filter_basic(self):
        """Test list_filter matches any item in lists."""
        col = pd.Series([["a", "b"], ["c", "d"], ["a", "d"]])
        to_filter = ["a"]

        result = main_page.list_filter(col, to_filter)

        assert result.sum() == 2  # First and third have 'a'

    def test_list_filter_multiple_matches(self):
        """Test list_filter with multiple filter items."""
        col = pd.Series([["a", "b"], ["c", "d"], ["a", "d"]])
        to_filter = ["a", "c"]

        result = main_page.list_filter(col, to_filter)

        assert result.sum() == 3  # All match

    def test_list_filter_with_nan(self):
        """Test list_filter includes NaN values."""
        col = pd.Series([["a", "b"], None, ["c", "d"]])
        to_filter = ["a"]

        result = main_page.list_filter(col, to_filter)

        assert result.sum() == 2  # First and NaN

    @pytest.mark.parametrize(
        ("scaling_method", "expected_min", "expected_max"),
        [
            ("min-max", 0.0, 1.0),
            ("rank", None, 1.0),  # min will vary based on ranking
        ],
    )
    def test_normalise(self, scaling_method, expected_min, expected_max):
        """Test normalise with different scaling methods."""
        df = pd.DataFrame({"col1": [1, 2, 3, 4, 5], "col2": [10, 20, 30, 40, 50]})

        result = main_page.normalise(df, scaling_method)

        assert isinstance(result, pd.DataFrame)
        if expected_min is not None:
            assert result["col1"].min() == expected_min
            assert result["col2"].min() == expected_min
        assert result["col1"].max() == expected_max
        assert result["col2"].max() == expected_max

    def test_update_score_col_structure(self):
        """Test update_score_col returns a Series."""
        df = pd.DataFrame({"Stars": [100, 200, 50], "Forks": [10, 20, 5]})

        # Mock session state
        st.session_state["scoring_Stars"] = 0.7
        st.session_state["scoring_Forks"] = 0.3
        st.session_state["scoring_method"] = "rank"

        result = main_page.update_score_col(df)

        assert isinstance(result, pd.Series)
        assert len(result) == len(df)
        assert (result >= 0).all()
        assert (result <= 100).all()

    @pytest.mark.parametrize("bins", [10, 30, 50])
    def test_distribution_table(self, bins):
        """Test _distribution_table with different bin counts."""
        col = pd.Series(np.random.randn(100), name="test")

        result = main_page._distribution_table(col, bins=bins)

        assert isinstance(result, pd.DataFrame)
        assert "x" in result.columns
        assert "y" in result.columns
        assert len(result) == bins


# ===== Tests for User Interaction Analysis page =====


class TestUserAnalysisFunctions:
    """Tests for user interaction analysis functions."""

    @pytest.fixture(scope="class")
    def user_classifications_df(self):
        """Load user classifications CSV (class-level fixture)."""
        return pd.read_csv(USER_STATS_DIR / "user_classifications.csv")

    @pytest.fixture(scope="class")
    def user_vis_table(self):
        """Create user analysis vis table (class-level fixture)."""
        return user_analysis.create_vis_table(USER_STATS_DIR)

    def test_create_vis_table_structure(self, user_vis_table):
        """Test create_vis_table returns DataFrame with expected columns."""
        assert isinstance(user_vis_table, pd.DataFrame)
        assert "classification" in user_vis_table.columns

    def test_map_repo_to_tool_structure(self, user_classifications_df):
        """Test map_repo_to_tool returns list of dicts."""
        result = user_analysis.map_repo_to_tool(user_classifications_df, "repos")

        assert isinstance(result, list)
        assert all(isinstance(item, dict) for item in result)
        assert all("repo" in item and "name" in item for item in result)


# ===== Tests for Project Development Metrics page =====


class TestDevMetricsFunctions:
    """Tests for project development metrics functions."""

    @pytest.fixture(scope="class")
    def dev_vis_table(self):
        """Create dev metrics vis table (class-level fixture)."""
        return dev_metrics.create_vis_table(USER_STATS_DIR / "repo_interactions.csv")

    @pytest.fixture(scope="class")
    def repo_interactions_csv(self):
        """Load user interactions CSV (class-level fixture)."""
        return pd.read_csv(USER_STATS_DIR / "repo_interactions.csv")

    @pytest.fixture
    def sample_interactions_df(self):
        """Create a sample interactions dataframe."""
        return pd.DataFrame(
            {
                "username": ["user1", "user2", "user1", "bot-action", "user3"],
                "repo": [
                    "org1/tool1",
                    "org2/tool2",
                    "org1/tool1",
                    "org1/tool1",
                    "org2/tool2",
                ],
                "interaction": ["issue", "pr", "commit", "pr", "issue"],
                "subtype": ["author", "author", None, "author", "comment"],
                "created": pd.to_datetime(
                    [
                        "2024-01-01",
                        "2024-01-02",
                        "2024-01-03",
                        "2024-01-04",
                        "2024-01-05",
                    ]
                ),
                "closed": pd.to_datetime([None, None, None, "2024-01-05", None]),
                "merged": pd.to_datetime([None, "2024-01-03", None, None, None]),
                "number": [1, 1, None, 2, 1],
            }
        )

    def test_create_vis_table_structure(self, dev_vis_table):
        """Test create_vis_table returns DataFrame with expected columns."""
        assert isinstance(dev_vis_table, pd.DataFrame)
        assert "username" in dev_vis_table.columns
        assert "repo" in dev_vis_table.columns
        assert "interaction" in dev_vis_table.columns
        assert pd.api.types.is_datetime64_any_dtype(dev_vis_table["created"])

    def test_create_vis_table_no_missing_critical_fields(self, dev_vis_table):
        """Test that create_vis_table drops rows missing username or repo."""
        assert dev_vis_table["username"].notna().all()
        assert dev_vis_table["repo"].notna().all()

    def test_map_repo_to_tool_structure(self, repo_interactions_csv):
        """Test map_repo_to_tool returns list of dicts."""
        result = dev_metrics.map_repo_to_tool(repo_interactions_csv, "repo")

        assert isinstance(result, list)
        assert all(isinstance(item, dict) for item in result)
        assert all("repo" in item and "name" in item for item in result)

    @pytest.mark.parametrize(
        ("hide_bots", "expected_min_count"),
        [
            (True, 0),  # May filter some or all
            (False, 5),  # Should keep all 5 rows
        ],
    )
    def test_filter_interactions_bot_handling(
        self, sample_interactions_df, hide_bots, expected_min_count
    ):
        """Test filter_interactions bot handling with hide_bots parameter."""
        result = dev_metrics.filter_interactions(
            sample_interactions_df, [], None, hide_bots=hide_bots
        )

        if hide_bots:
            # When hiding bots, check that bot patterns are filtered
            df_with_bot = sample_interactions_df.copy()
            df_with_bot.loc[3, "username"] = "action-bot"
            result_filtered = dev_metrics.filter_interactions(
                df_with_bot, [], None, hide_bots=True
            )
            assert "action-bot" not in result_filtered["username"].values
        else:
            # When not hiding bots, all rows should be kept
            assert len(result) >= expected_min_count

    def test_filter_interactions_filters_tools(self, sample_interactions_df):
        """Test filter_interactions filters by selected tools."""
        repo_map = [{"repo": "org1/tool1", "name": "Tool1"}]

        result = dev_metrics.filter_interactions(
            sample_interactions_df, repo_map, ["Tool1"], hide_bots=False
        )

        assert len(result) == 3  # Only org1/tool1 interactions
        assert all(result["repo"] == "org1/tool1")

    def test_filter_interactions_no_tool_filter(self, sample_interactions_df):
        """Test filter_interactions with no tool filter (selected_tools=None)."""
        result = dev_metrics.filter_interactions(
            sample_interactions_df, [], None, hide_bots=False
        )

        assert len(result) == 5  # All interactions

    def test_date_filter_basic(self, sample_interactions_df):
        """Test date_filter filters by date range."""
        result = dev_metrics.date_filter(
            sample_interactions_df, ("2024-01-02", "2024-01-04")
        )

        # Date filter checks created, closed, and merged dates
        # Rows with any of those dates in range should be included
        assert len(result) >= 2
        assert result["created"].min() >= pd.Timestamp("2024-01-02")
        # The bot-action row has closed date on 2024-01-05, so it should be excluded
        assert all(
            (
                result["created"].between("2024-01-02", "2024-01-04")
                | result["closed"].between("2024-01-02", "2024-01-04")
                | result["merged"].between("2024-01-02", "2024-01-04")
            ).fillna(False)
        )

    def test_date_filter_uses_closed_and_merged(self, sample_interactions_df):
        """Test date_filter considers closed and merged dates."""
        # The date_filter function filters by all three date columns sequentially
        # A row must have ALL date columns (or their fillna equivalents) in range
        df = sample_interactions_df.copy()

        # Create a scenario where all dates are in the specified range
        df.loc[4, "created"] = pd.Timestamp("2024-01-05")

        result = dev_metrics.date_filter(df, ("2024-01-04", "2024-01-05"))

        # Should include rows where all date fields (using created as fallback) are in range
        assert len(result) >= 1
        # All returned rows should have created date in range
        assert all(result["created"].between("2024-01-04", "2024-01-05"))

    @pytest.mark.parametrize("resample", ["1D", "1W"])
    def test_get_totals(self, sample_interactions_df, resample):
        """Test get_totals with different resampling frequencies."""
        result = dev_metrics.get_totals(sample_interactions_df, "created", resample)

        assert isinstance(result, pd.DataFrame)
        assert "Total Issues" in result.columns
        assert "Total PRs" in result.columns
        assert "Total Commits" in result.columns

    @pytest.mark.parametrize(
        ("interaction", "time_col", "expected_count"),
        [("pr", "merged", 1), ("pr", "closed", 1)],
    )
    def test_get_complete_time(
        self, sample_interactions_df, interaction, time_col, expected_count
    ):
        """Test get_complete_time for different interactions and time columns."""
        result = dev_metrics.get_complete_time(
            sample_interactions_df, interaction, time_col
        )

        assert isinstance(result, pd.Series)
        assert len(result) == expected_count

    def test_get_complete_time_only_authors(self, sample_interactions_df):
        """Test get_complete_time only considers author subtype."""
        df = sample_interactions_df.copy()
        df.loc[4, "interaction"] = "pr"
        df.loc[4, "merged"] = pd.Timestamp("2024-01-10")

        result = dev_metrics.get_complete_time(df, "pr", "merged")

        # Should only have 1 result (author), not comment
        assert len(result) == 1

    def test_get_engagement_structure(self, sample_interactions_df):
        """Test _get_engagement returns Series with engagement counts."""
        result = dev_metrics._get_engagement(sample_interactions_df, "issue")

        assert isinstance(result, pd.Series)
        # Index should be (number, repo) MultiIndex with named levels
        assert result.index.names == ["number", "repo"]

    def test_get_engagement_includes_zeros(self, sample_interactions_df):
        """Test _get_engagement includes zero engagement for items without comments."""
        result = dev_metrics._get_engagement(sample_interactions_df, "issue")

        # Should have entries for all unique issue numbers
        assert len(result) >= 1

    def test_get_engagement_counts_subtypes(self, sample_interactions_df):
        """Test _get_engagement counts comment, reaction, and review subtypes."""
        # Add more engagement
        new_row = pd.DataFrame(
            {
                "username": ["user2"],
                "repo": ["org2/tool2"],
                "interaction": ["issue"],
                "subtype": ["reaction"],
                "created": [pd.Timestamp("2024-01-06")],
                "closed": [None],
                "merged": [None],
                "number": [1],
            }
        )
        df = pd.concat([sample_interactions_df, new_row], ignore_index=True)

        result = dev_metrics._get_engagement(df, "issue")

        # Issue 1 in org2/tool2 should have engagement count of 2 (comment + reaction)
        assert result.loc[(1, "org2/tool2")] == 2.0
